# Overlay the theoretical density curve
x = np.linspace(min(sample_sums), max(sample_sums), 10000)
th_mean = 10 * mean
th_variance = 10 * sigma_squared
th_std = np.sqrt(th_variance)
th_pdf = stats.norm.pdf(x, th_mean, th_std)
plt.plot(x, th_pdf, 'r-', lw=2, label='Theoretical Density')
# Adding labels and legend
plt.xlabel('Sum of 10 Samples')
plt.ylabel('Density')
plt.title('Histogram of Sample Sums vs Theoretical Distribution')
plt.legend()
plt.grid(True)
plt.show()
# - We observe that the histogram of the 10,000 sample sums closely
# matches the theoretical normal distribution curve with mean 10 * mu and variance 10 * sigma_squared.
# This indicates that the observed distribution aligns well with the theoretical distribution, as expected.
import numpy as np
import matplotlib.pyplot as plt
import scipy.stats as stats
mean = 23
sigma_squared = 3.6
sigma = np.sqrt(sigma_squared)
n_samples = 10
n_simulations = 10000
# (2) Generate a sample of size 10 from the Normal distribution
# with parameters mean = 23 and sigma_squared = 3.6 and the compute the sum
# of the generated observations
sample = np.random.normal(mean, sigma, n_samples)
sample_sum = np.sum(sample)
_ = sample_sum # Avoid printing the sum
print(f"Sum of a single generated sample of size 10: {sample_sum}")
# (3) Simulate 10000 times part (2) and compute the sum
#of the generated samples of size 10
samples = []
for _ in range(n_simulations):
sample = np.random.normal(mean, sigma, n_samples)
samples.append(sample)
# Compute the sums of the generated samples of size 10
sample_sums = [np.sum(sample) for sample in samples]
# Convert list to numpy array
# sample_sums = np.array(sample_sums)
# (4) Plot the histogram of the 10000 observed statistics from part (3).
# Then show the density curve of the theoretical distribution you
# found in part (1) on the histogram.
plt.hist(sample_sums, bins=50, density=True, alpha=0.6, color='g', label='Simulated Sums')
# Overlay the theoretical density curve
x = np.linspace(min(sample_sums), max(sample_sums), 10000)
th_mean = 10 * mean
th_variance = 10 * sigma_squared
th_std = np.sqrt(th_variance)
th_pdf = stats.norm.pdf(x, th_mean, th_std)
plt.plot(x, th_pdf, 'r-', lw=2, label='Theoretical Density')
# Adding labels and legend
plt.xlabel('Sum of 10 Samples')
plt.ylabel('Density')
plt.title('Histogram of Sample Sums vs Theoretical Distribution')
plt.legend()
plt.grid(True)
plt.show()
# - We observe that the histogram of the 10,000 sample sums closely
# matches the theoretical normal distribution curve with mean 10 * mu and variance 10 * sigma_squared.
# This indicates that the observed distribution aligns well with the theoretical distribution, as expected.
import numpy as np
import matplotlib.pyplot as plt
import scipy.stats as stats
mean = 23
sigma_squared = 3.6
sigma = np.sqrt(sigma_squared)
n_samples = 10
n_simulations = 10000
# (2) Generate a sample of size 10 from the Normal distribution
# with parameters mean = 23 and sigma_squared = 3.6 and the compute the sum
# of the generated observations
sample = np.random.normal(mean, sigma, n_samples)
sample_sum = np.sum(sample)
print(f"Sum of a single generated sample of size 10: {sample_sum}")
print()
print()
print()
# (3) Simulate 10000 times part (2) and compute the sum
#of the generated samples of size 10
samples = []
for _ in range(n_simulations):
sample = np.random.normal(mean, sigma, n_samples)
samples.append(sample)
# Compute the sums of the generated samples of size 10
sample_sums = [np.sum(sample) for sample in samples]
# Convert list to numpy array
# sample_sums = np.array(sample_sums)
# (4) Plot the histogram of the 10000 observed statistics from part (3).
# Then show the density curve of the theoretical distribution you
# found in part (1) on the histogram.
plt.hist(sample_sums, bins=50, density=True, alpha=0.6, color='g', label='Simulated Sums')
# Overlay the theoretical density curve
x = np.linspace(min(sample_sums), max(sample_sums), 10000)
th_mean = 10 * mean
th_variance = 10 * sigma_squared
th_std = np.sqrt(th_variance)
th_pdf = stats.norm.pdf(x, th_mean, th_std)
plt.plot(x, th_pdf, 'r-', lw=2, label='Theoretical Density')
# Adding labels and legend
plt.xlabel('Sum of 10 Samples')
plt.ylabel('Density')
plt.title('Histogram of Sample Sums vs Theoretical Distribution')
plt.legend()
plt.grid(True)
plt.show()
# - We observe that the histogram of the 10,000 sample sums closely
# matches the theoretical normal distribution curve with mean 10 * mu and variance 10 * sigma_squared.
# This indicates that the observed distribution aligns well with the theoretical distribution, as expected.
import numpy as np
import matplotlib.pyplot as plt
import scipy.stats as stats
mean = 23
sigma_squared = 3.6
sigma = np.sqrt(sigma_squared)
n_samples = 10
n_simulations = 10000
# (2) Generate a sample of size 10 from the Normal distribution
# with parameters mean = 23 and sigma_squared = 3.6 and the compute the sum
# of the generated observations
sample = np.random.normal(mean, sigma, n_samples)
sample_sum = np.sum(sample)
print()
print()
print()
print(f"Sum of a single generated sample of size 10: {sample_sum}")
print()
print()
print()
# (3) Simulate 10000 times part (2) and compute the sum
#of the generated samples of size 10
samples = []
for _ in range(n_simulations):
sample = np.random.normal(mean, sigma, n_samples)
samples.append(sample)
# Compute the sums of the generated samples of size 10
sample_sums = [np.sum(sample) for sample in samples]
# Convert list to numpy array
# sample_sums = np.array(sample_sums)
# (4) Plot the histogram of the 10000 observed statistics from part (3).
# Then show the density curve of the theoretical distribution you
# found in part (1) on the histogram.
plt.hist(sample_sums, bins=50, density=True, alpha=0.6, color='g', label='Simulated Sums')
# Overlay the theoretical density curve
x = np.linspace(min(sample_sums), max(sample_sums), 10000)
th_mean = 10 * mean
th_variance = 10 * sigma_squared
th_std = np.sqrt(th_variance)
th_pdf = stats.norm.pdf(x, th_mean, th_std)
plt.plot(x, th_pdf, 'r-', lw=2, label='Theoretical Density')
# Adding labels and legend
plt.xlabel('Sum of 10 Samples')
plt.ylabel('Density')
plt.title('Histogram of Sample Sums vs Theoretical Distribution')
plt.legend()
plt.grid(True)
plt.show()
# - We observe that the histogram of the 10,000 sample sums closely
# matches the theoretical normal distribution curve with mean 10 * mu and variance 10 * sigma_squared.
# This indicates that the observed distribution aligns well with the theoretical distribution, as expected.
import numpy as np
import matplotlib.pyplot as plt
import scipy.stats as stats
mean = 23
sigma_squared = 3.6
sigma = np.sqrt(sigma_squared)
n_samples = 10
n_simulations = 10000
# (2) Generate a sample of size 10 from the Normal distribution
# with parameters mean = 23 and sigma_squared = 3.6 and the compute the sum
# of the generated observations
sample = np.random.normal(mean, sigma, n_samples)
sample_sum = np.sum(sample)
print(f"Sum of a single generated sample of size 10: {sample_sum}")
# (3) Simulate 10000 times part (2) and compute the sum
#of the generated samples of size 10
samples = []
for _ in range(n_simulations):
sample = np.random.normal(mean, sigma, n_samples)
samples.append(sample)
# Compute the sums of the generated samples of size 10
sample_sums = [np.sum(sample) for sample in samples]
# Convert list to numpy array
# sample_sums = np.array(sample_sums)
# (4) Plot the histogram of the 10000 observed statistics from part (3).
# Then show the density curve of the theoretical distribution you
# found in part (1) on the histogram.
plt.hist(sample_sums, bins=50, density=True, alpha=0.6, color='g', label='Simulated Sums')
# Overlay the theoretical density curve
x = np.linspace(min(sample_sums), max(sample_sums), 10000)
th_mean = 10 * mean
th_variance = 10 * sigma_squared
th_std = np.sqrt(th_variance)
th_pdf = stats.norm.pdf(x, th_mean, th_std)
plt.plot(x, th_pdf, 'r-', lw=2, label='Theoretical Density')
# Adding labels and legend
plt.xlabel('Sum of 10 Samples')
plt.ylabel('Density')
plt.title('Histogram of Sample Sums vs Theoretical Distribution')
plt.legend()
plt.grid(True)
plt.show()
# - We observe that the histogram of the 10,000 sample sums closely
# matches the theoretical normal distribution curve with mean 10 * mu and variance 10 * sigma_squared.
# This indicates that the observed distribution aligns well with the theoretical distribution, as expected.
import numpy as np
import matplotlib.pyplot as plt
import scipy.stats as stats
mean = 23
sigma_squared = 3.6
sigma = np.sqrt(sigma_squared)
n_samples = 10
n_simulations = 10000
# (2) Generate a sample of size 10 from the Normal distribution
# with parameters mean = 23 and sigma_squared = 3.6 and the compute the sum
# of the generated observations
sample = np.random.normal(mean, sigma, n_samples)
sample_sum = np.sum(sample)
print(f"Sum of a single generated sample of size 10: {sample_sum}")
# (3) Simulate 10000 times part (2) and compute the sum
#of the generated samples of size 10
samples = []
for _ in range(n_simulations):
sample = np.random.normal(mean, sigma, n_samples)
samples.append(sample)
# Compute the sums of the generated samples of size 10
sample_sums = [np.sum(sample) for sample in samples]
# Convert list to numpy array
# sample_sums = np.array(sample_sums)
# (4) Plot the histogram of the 10000 observed statistics from part (3).
# Then show the density curve of the theoretical distribution you
# found in part (1) on the histogram.
plt.hist(sample_sums, bins=50, density=True, alpha=0.6, color='g', label='Simulated Sums')
# Overlay the theoretical density curve
x = np.linspace(min(sample_sums), max(sample_sums), 10000)
th_mean = 10 * mean
th_variance = 10 * sigma_squared
th_std = np.sqrt(th_variance)
th_pdf = stats.norm.pdf(x, th_mean, th_std)
plt.plot(x, th_pdf, 'r-', lw=2, label='Theoretical Density')
# Adding labels and legend
plt.xlabel('Sum of 10 Samples')
plt.ylabel('Density')
plt.title('Histogram of Sample Sums vs Theoretical Distribution')
plt.legend()
plt.grid(True)
plt.show()
# - We observe that the histogram of the 10,000 sample sums closely
# matches the theoretical normal distribution curve with mean 10 * mu and variance 10 * sigma_squared.
# This indicates that the observed distribution aligns well with the theoretical distribution, as expected.
import numpy as np
import matplotlib.pyplot as plt
import scipy.stats as stats
mean = 23
sigma_squared = 3.6
sigma = np.sqrt(sigma_squared)
n_samples = 10
n_simulations = 10000
# (2) Generate a sample of size 10 from the Normal distribution
# with parameters μ = 23 and σ2 = 3.6 and the compute the sum
# of the generated observations
sample = np.random.normal(mean, sigma, n_samples)
sample_sum = np.sum(sample)
print(f"Sum of a single generated sample of size 10: {sample_sum}")
# (3) Simulate 10000 times part (2) and compute the sum
#of the generated samples of size 10
samples = []
for _ in range(n_simulations):
sample = np.random.normal(mean, sigma, n_samples)
samples.append(sample)
# (4) Compute the sums of the generated samples of size 10
sample_sums = [np.sum(sample) for sample in samples]
# Convert list to numpy array
sample_sums = np.array(sample_sums)
# (4) Plot the histogram of the 10000 observed statistics from part (3).
# Then show the density curve of the theoretical distribution you
# found in part (1) on the histogram.
plt.hist(sample_sums, bins=50, density=True, alpha=0.6, color='g', label='Simulated Sums')
# Overlay the theoretical density curve
x = np.linspace(min(sample_sums), max(sample_sums), 10000)
th_mean = 10 * mean
th_variance = 10 * sigma_squared
th_std = np.sqrt(th_variance)
th_pdf = stats.norm.pdf(x, th_mean, th_std)
plt.plot(x, th_pdf, 'r-', lw=2, label='Theoretical Density')
# Adding labels and legend
plt.xlabel('Sum of 10 Samples')
plt.ylabel('Density')
plt.title('Histogram of Sample Sums vs Theoretical Distribution')
plt.legend()
plt.grid(True)
plt.show()
# - We observe that the histogram of the 10,000 sample sums closely
# matches the theoretical normal distribution curve with mean 10 * mu and variance 10 * sigma_squared.
# This indicates that the observed distribution aligns well with the theoretical distribution, as expected.
reticulate::repl_python()
# Define the value of c
c <- sqrt(3) - 1
# Define the PDF function
f <- function(x) {
3 / (1 + x)^3
}
# Define the range for plotting
x_vals <- seq(0, c, length.out = 1000)
# Calculate the y-values for each x
y_vals <- f(x_vals)
# Plot the PDF
plot(x_vals, y_vals, type = "l", col = "blue", lwd = 2,
main = "Probability Density Function of X",
xlab = "x", ylab = "f(x)")
# Define the function for the cumulative distribution (inverse transformation method)
func_inv <- function(u) {
(2 * (1 - u))^(-1/2) - 1
}
# Simulate 1000 random observations
set.seed(123)  # Set a seed for reproducibility
u_vals <- runif(1000)
simulated_data <- func_inv(u_vals)
# Define the function for the cumulative distribution (inverse transformation method)
func_inv <- function(u) {
(2 * (1 - u))^(-1/2) - 1
}
# Simulate 1000 random observations
set.seed(123)  # Set a seed for reproducibility
u_vals <- runif(1000)
simulated_data <- func_inv(u_vals)
# Estimate mean and variance
estimated_mean <- mean(simulated_data)
estimated_variance <- var(simulated_data)
# Print the results
cat("Estimated Mean:", estimated_mean, "\n")
cat("Estimated Variance:", estimated_variance, "\n")
# Define the PDF function
f <- function(x) {
3 / (1 + x)^3
}
# Set the value of c we found earlier
c <- sqrt(3) - 1
# Number of samples to generate
n <- 1000
# Set up the rejection sampling
set.seed(123)  # Set seed for reproducibility
# Find maximum of f(x) on [0, c] for rejection sampling
f_max <- f(0)  # Since the PDF is decreasing from 0 to c
# Generate samples using rejection sampling
samples <- numeric(n)
i <- 1
while (i <= n) {
x <- runif(1, 0, c)       # Generate a candidate from [0, c]
y <- runif(1, 0, f_max)   # Generate a uniform value between 0 and f_max
if (y <= f(x)) {          # Accept if the point is below the curve
samples[i] <- x
i <- i + 1
}
}
# Print the first few samples
head(samples)
# Define the function for the cumulative distribution (inverse transformation method)
func_inv <- function(u) {
(2 * (1 - u))^(-1/2) - 1
}
# Simulate 1000 random observations
set.seed(123)  # Set a seed for reproducibility
u_vals <- runif(1000)
simulated_data <- func_inv(u_vals)
# Estimate mean and variance
estimated_mean <- mean(simulated_data)
estimated_variance <- var(simulated_data)
# Print the results
cat("Estimated Mean:", estimated_mean, "\n")
cat("Estimated Variance:", estimated_variance, "\n")
# Define the function for the cumulative distribution (inverse transformation method)
func_inv <- function(u) {
(2 * (1 - u))^(-1/2) - 1
}
# Simulate 1000 random observations
set.seed(123)  # Set a seed for reproducibility
u_vals <- runif(1000)
simulated_data <- func_inv(u_vals)
# Estimate mean and variance
estimated_mean <- mean(simulated_data)
estimated_variance <- var(simulated_data)
# Print the results
cat("Estimated Mean:", estimated_mean, "\n")
cat("Estimated Variance:", estimated_variance, "\n")
# Define the function for the cumulative distribution (inverse transformation method)
func_inv <- function(u) {
(2 * (1 - u))^(-1/2) - 1
}
# Simulate 1000 random observations
set.seed(123)  # Set a seed for reproducibility
u_vals <- runif(1000)
simulated_data <- func_inv(u_vals)
# Estimate mean and variance
estimated_mean <- mean(simulated_data)
estimated_variance <- var(simulated_data)
# Print the results
cat("Estimated Mean:", estimated_mean, "\n")
cat("Estimated Variance:", estimated_variance, "\n")
# Define the function for the cumulative distribution (inverse transformation method)
func_inv <- function(u) {
(2 * (1 - u))^(-1/2) - 1
}
# Simulate 1000 random observations
set.seed(123)  # Set a seed for reproducibility
u_vals <- runif(1000)
simulated_data <- func_inv(u_vals)
# Estimate mean and variance
estimated_mean <- mean(simulated_data)
estimated_variance <- var(simulated_data)
# Print the results
cat("Estimated Mean:", estimated_mean, "\n")
cat("Estimated Variance:", estimated_variance, "\n")
# Define the function for the cumulative distribution (inverse transformation method)
func_inv <- function(u) {
(2 * (1 - u))^(-1/2) - 1
}
# Simulate 1000 random observations
set.seed(123)  # Set a seed for reproducibility
u_vals <- runif(1000)
simulated_data <- func_inv(u_vals)
# Estimate mean and variance
estimated_mean <- mean(simulated_data)
estimated_variance <- var(simulated_data)
# Print the results
cat("Estimated Mean:", estimated_mean, "\n")
cat("Estimated Variance:", estimated_variance, "\n")
# Define the function for the cumulative distribution (inverse transformation method)
func_inv <- function(u) {
(2 * (1 - u))^(-1/2) - 1
}
# Simulate 1000 random observations
set.seed(123)  # Set a seed for reproducibility
u_vals <- runif(1000)
simulated_data <- func_inv(u_vals)
# Estimate mean and variance
estimated_mean <- mean(simulated_data)
estimated_variance <- var(simulated_data)
# Print the results
cat("Estimated Mean:", estimated_mean, "\n")
cat("Estimated Variance:", estimated_variance, "\n")
unlink("as2_6607_f24 (2)_cache", recursive = TRUE)
unlink("as2_6607_f24 (2)_cache", recursive = TRUE)
reticulate::repl_python()
# (a). Incorporate bracket broadening into the bisection method. Note that broadening
# is not guaranteed to ﬁnd x l and x r such that f(x l )f(x r ) <= 0, so you should
# include a limit on the number of times it can be tried.
bisection_broadening <- function(f, xl, xr) {
# Initialize variables
iter <- 0
broaden_count <- 0
# The maximum number of iterations here is 100 and could vary
while (iter < 100) {
# Calculate midpoint
m <- (xl + xr) / 2
w <- xr - xl
# Check if the product of f(xl) and f(xr) is less than or equal to zero
if (f(xl) * f(xr) <= 0) {
# Bisection process with a tolerance of 1e-5
if (abs(xr - xl) < 1e-5) {
return(m)  # Root found within tolerance
}
if (f(xl) * f(m) < 0) {
xr <- m
} else {
xl <- m
}
} else {
# Broaden the interval, maximum number of times the interval can
# be broadened in this case 5; changeable as well
if (broaden_count < 5) {
broaden_count <- broaden_count + 1
xl <- m - w
xr <- m + w
} else {
stop("Bracket broadening limit reached without finding a valid interval.")
}
}
iter <- iter + 1
}
stop("Maximum iterations reached without finding the root.")
}
# Define the function f(x)
f <- function(x) {
(x - 1)^3 - 2 * x^2 + 10 - sin(x)
}
# (b). Use your modiﬁed function to ﬁnd a root of f(x)
root <- bisection_broadening(f, 1, 2)
print(root)
pip install numpy scikit-learn
library(reticulate)
reticulate::repl_python()
install.packages("reticulate")
library(reticulate)
install.packages("reticulate")
library(reticulate)
reticulate::repl_python()
# Install and load the reticulate package
if (!requireNamespace("reticulate", quietly = TRUE)) {
install.packages("reticulate")
}
library(reticulate)
# Install and load the reticulate package
if (!requireNamespace("reticulate", quietly = TRUE)) {
install.packages("reticulate")
}
library(reticulate)
reticulate::repl_python()
py_install("scikit-learn")
reticulate::repl_python()
